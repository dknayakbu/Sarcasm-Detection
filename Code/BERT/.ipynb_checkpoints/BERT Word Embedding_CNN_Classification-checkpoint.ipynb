{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import warnings\n",
    "import keras\n",
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Embedding, Bidirectional, Dense, LSTM, Conv1D, MaxPooling1D, Flatten, Reshape, TimeDistributed, Dropout\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw=pd.read_json(r\"./../../Dataset/Sarcasm_Headlines_Dataset_v2/Sarcasm_Headlines_Dataset_v2.json\",lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=df_raw.loc[:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28619, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['is_sarcastic', 'headline', 'article_link'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "      <th>article_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sarcastic                                           headline  \\\n",
       "0             1  thirtysomething scientists unveil doomsday clo...   \n",
       "1             0  dem rep. totally nails why congress is falling...   \n",
       "2             0  eat your veggies: 9 deliciously different recipes   \n",
       "3             1  inclement weather prevents liar from getting t...   \n",
       "4             1  mother comes pretty close to using word 'strea...   \n",
       "\n",
       "                                        article_link  \n",
       "0  https://www.theonion.com/thirtysomething-scien...  \n",
       "1  https://www.huffingtonpost.com/entry/donna-edw...  \n",
       "2  https://www.huffingtonpost.com/entry/eat-your-...  \n",
       "3  https://local.theonion.com/inclement-weather-p...  \n",
       "4  https://www.theonion.com/mother-comes-pretty-c...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.08782839  0.06258331 -0.12000587 ... -0.33156553  0.5002954\n",
      "   0.1805836 ]\n",
      " [-0.43426287 -0.50481713 -0.36135322 ... -0.02944355  0.34979802\n",
      "   0.26927984]\n",
      " [-0.13752083 -0.09303751  0.14121507 ... -0.0079867   0.26747227\n",
      "   0.29764438]\n",
      " ...\n",
      " [-0.28889391 -0.20626098  0.15944281 ... -0.02881556  0.36084583\n",
      "   0.32674789]\n",
      " [-0.66664398 -0.10732649 -0.48685697 ... -0.26801217  0.5380348\n",
      "   0.31238717]\n",
      " [-0.05215537  0.08621484  0.14538945 ... -0.13530289  0.40199804\n",
      "   0.26933154]]\n"
     ]
    }
   ],
   "source": [
    "# load numpy array from npy file\n",
    "from numpy import load\n",
    "# load array\n",
    "embeddings_npy = load('embeddings.npy')\n",
    "# print the array\n",
    "print(embeddings_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28619, 768)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_npy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28619, 768, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_npy_3d=embeddings_npy.reshape(-1,768,1)\n",
    "embeddings_npy_3d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28619, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df['is_sarcastic']\n",
    "labels=np.array(labels).reshape(-1,1)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and test data splits\n",
    "x_train, x_test, y_train, y_test = train_test_split(embeddings_npy_3d, labels, test_size = 0.2, random_state = 0)\n",
    "x_train, x_val,  y_train, y_val  = train_test_split(x_train, y_train, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18316, 768, 1)\n",
      "(18316, 1)\n",
      "(4579, 768, 1)\n",
      "(4579, 1)\n",
      "(5724, 768, 1)\n",
      "(5724, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 766, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 383, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               91600     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 92,213\n",
      "Trainable params: 92,213\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 18316 samples, validate on 4579 samples\n",
      "Epoch 1/30\n",
      "18316/18316 [==============================] - 24s 1ms/step - loss: 0.6866 - accuracy: 0.5308 - val_loss: 0.6866 - val_accuracy: 0.5370\n",
      "Epoch 2/30\n",
      "18316/18316 [==============================] - 22s 1ms/step - loss: 0.6608 - accuracy: 0.6015 - val_loss: 0.6510 - val_accuracy: 0.6174\n",
      "Epoch 3/30\n",
      "18316/18316 [==============================] - 21s 1ms/step - loss: 0.6510 - accuracy: 0.6265 - val_loss: 0.6440 - val_accuracy: 0.6185\n",
      "Epoch 4/30\n",
      "18316/18316 [==============================] - 21s 1ms/step - loss: 0.6290 - accuracy: 0.6412 - val_loss: 0.6230 - val_accuracy: 0.6412\n",
      "Epoch 5/30\n",
      "18316/18316 [==============================] - 21s 1ms/step - loss: 0.6084 - accuracy: 0.6659 - val_loss: 0.6072 - val_accuracy: 0.6689\n",
      "Epoch 6/30\n",
      "18316/18316 [==============================] - 21s 1ms/step - loss: 0.6010 - accuracy: 0.6745 - val_loss: 0.5949 - val_accuracy: 0.6890\n",
      "Epoch 7/30\n",
      "18316/18316 [==============================] - 21s 1ms/step - loss: 0.5912 - accuracy: 0.6897 - val_loss: 0.5897 - val_accuracy: 0.6903\n",
      "Epoch 8/30\n",
      "18316/18316 [==============================] - 21s 1ms/step - loss: 0.5852 - accuracy: 0.6958 - val_loss: 0.6191 - val_accuracy: 0.6530\n",
      "Epoch 9/30\n",
      "18316/18316 [==============================] - 21s 1ms/step - loss: 0.5772 - accuracy: 0.6999 - val_loss: 0.5675 - val_accuracy: 0.7106\n",
      "Epoch 10/30\n",
      "18316/18316 [==============================] - 21s 1ms/step - loss: 0.5822 - accuracy: 0.6938 - val_loss: 0.5806 - val_accuracy: 0.6958\n",
      "Epoch 11/30\n",
      "18316/18316 [==============================] - 21s 1ms/step - loss: 0.5684 - accuracy: 0.7081 - val_loss: 0.5631 - val_accuracy: 0.7150\n",
      "Epoch 12/30\n",
      "18316/18316 [==============================] - 21s 1ms/step - loss: 0.5608 - accuracy: 0.7130 - val_loss: 0.5568 - val_accuracy: 0.7189\n",
      "Epoch 13/30\n",
      "18316/18316 [==============================] - 22s 1ms/step - loss: 0.5523 - accuracy: 0.7180 - val_loss: 0.5477 - val_accuracy: 0.7216\n",
      "Epoch 14/30\n",
      "18316/18316 [==============================] - 21s 1ms/step - loss: 0.5424 - accuracy: 0.7246 - val_loss: 0.5390 - val_accuracy: 0.7279\n",
      "Epoch 15/30\n",
      "18316/18316 [==============================] - 21s 1ms/step - loss: 0.5252 - accuracy: 0.7389 - val_loss: 0.5357 - val_accuracy: 0.7329\n",
      "Epoch 16/30\n",
      "18316/18316 [==============================] - 21s 1ms/step - loss: 0.5260 - accuracy: 0.7368 - val_loss: 0.5182 - val_accuracy: 0.7406\n",
      "Epoch 17/30\n",
      "18316/18316 [==============================] - 21s 1ms/step - loss: 0.5182 - accuracy: 0.7413 - val_loss: 0.5053 - val_accuracy: 0.7530\n",
      "Epoch 18/30\n",
      "18316/18316 [==============================] - 21s 1ms/step - loss: 0.5075 - accuracy: 0.7516 - val_loss: 0.5350 - val_accuracy: 0.7246\n",
      "Epoch 19/30\n",
      "18316/18316 [==============================] - 22s 1ms/step - loss: 0.5462 - accuracy: 0.7222 - val_loss: 0.5388 - val_accuracy: 0.7285\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 20/30\n",
      "18316/18316 [==============================] - 20s 1ms/step - loss: 0.5306 - accuracy: 0.7340 - val_loss: 0.5194 - val_accuracy: 0.7410\n",
      "Epoch 21/30\n",
      "18316/18316 [==============================] - 21s 1ms/step - loss: 0.5121 - accuracy: 0.7433 - val_loss: 0.5061 - val_accuracy: 0.7523\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 22/30\n",
      "18316/18316 [==============================] - 21s 1ms/step - loss: 0.4952 - accuracy: 0.7562 - val_loss: 0.4954 - val_accuracy: 0.7572\n",
      "Epoch 23/30\n",
      "18316/18316 [==============================] - 20s 1ms/step - loss: 0.4825 - accuracy: 0.7669 - val_loss: 0.4843 - val_accuracy: 0.7681\n",
      "Epoch 24/30\n",
      "18316/18316 [==============================] - 20s 1ms/step - loss: 0.4742 - accuracy: 0.7737 - val_loss: 0.4794 - val_accuracy: 0.7703\n",
      "Epoch 25/30\n",
      "18316/18316 [==============================] - 21s 1ms/step - loss: 0.4712 - accuracy: 0.7751 - val_loss: 0.4812 - val_accuracy: 0.7692\n",
      "Epoch 26/30\n",
      "18316/18316 [==============================] - 21s 1ms/step - loss: 0.4641 - accuracy: 0.7786 - val_loss: 0.4701 - val_accuracy: 0.7768\n",
      "Epoch 27/30\n",
      "18316/18316 [==============================] - 21s 1ms/step - loss: 0.4637 - accuracy: 0.7813 - val_loss: 0.4662 - val_accuracy: 0.7779\n",
      "Epoch 28/30\n",
      "18316/18316 [==============================] - 21s 1ms/step - loss: 0.4628 - accuracy: 0.7787 - val_loss: 0.4679 - val_accuracy: 0.7792\n",
      "Epoch 29/30\n",
      "18316/18316 [==============================] - 21s 1ms/step - loss: 0.4604 - accuracy: 0.7814 - val_loss: 0.4668 - val_accuracy: 0.7799\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 30/30\n",
      "18316/18316 [==============================] - 21s 1ms/step - loss: 0.4546 - accuracy: 0.7864 - val_loss: 0.4647 - val_accuracy: 0.7799\n",
      "score: 46.05\n",
      "Accuracy: 77.64%\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.50, patience=2, verbose=1, mode='auto', cooldown=0, min_lr=0.00001)\n",
    "\n",
    "early = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "model1 = Sequential()\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu',input_shape=(768,1)))\n",
    "model.add(Conv1D(128, 3, activation='relu',input_shape=(768,1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())\n",
    "\n",
    "adam = optimizers.Adam( beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history  = model.fit(np.array(x_train), np.array(y_train),\n",
    " epochs= 30,\n",
    " batch_size = 500,\n",
    " validation_data = (np.array(x_val), np.array(y_val)), \n",
    " callbacks = [reduce_lr, early]\n",
    ")\n",
    "\n",
    "score,acc = model.evaluate(x_test, y_test, verbose = 2)\n",
    "print(\"score: %.2f\" % (score*100))\n",
    "print(\"Accuracy: %.2f%%\" % (acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 766, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 764, 256)          98560     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 195584)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 391170    \n",
      "=================================================================\n",
      "Total params: 490,242\n",
      "Trainable params: 490,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 18316 samples, validate on 4579 samples\n",
      "Epoch 1/30\n",
      "18316/18316 [==============================] - 11s 577us/step - loss: 0.7108 - accuracy: 0.5510 - val_loss: 0.6491 - val_accuracy: 0.7519\n",
      "Epoch 2/30\n",
      "18316/18316 [==============================] - 7s 397us/step - loss: 0.5415 - accuracy: 0.7699 - val_loss: 0.4864 - val_accuracy: 0.7877\n",
      "Epoch 3/30\n",
      "18316/18316 [==============================] - 7s 397us/step - loss: 0.4266 - accuracy: 0.8111 - val_loss: 0.3989 - val_accuracy: 0.8207\n",
      "Epoch 4/30\n",
      "18316/18316 [==============================] - 7s 398us/step - loss: 0.3812 - accuracy: 0.8315 - val_loss: 0.3830 - val_accuracy: 0.8268\n",
      "Epoch 5/30\n",
      "18316/18316 [==============================] - 7s 398us/step - loss: 0.3465 - accuracy: 0.8483 - val_loss: 0.3537 - val_accuracy: 0.8434\n",
      "Epoch 6/30\n",
      "18316/18316 [==============================] - 7s 397us/step - loss: 0.3235 - accuracy: 0.8619 - val_loss: 0.3284 - val_accuracy: 0.8589\n",
      "Epoch 7/30\n",
      "18316/18316 [==============================] - 7s 398us/step - loss: 0.3093 - accuracy: 0.8671 - val_loss: 0.3285 - val_accuracy: 0.8578\n",
      "Epoch 8/30\n",
      "18316/18316 [==============================] - 7s 398us/step - loss: 0.2961 - accuracy: 0.8733 - val_loss: 0.3444 - val_accuracy: 0.8460\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 9/30\n",
      "18316/18316 [==============================] - 7s 398us/step - loss: 0.2826 - accuracy: 0.8813 - val_loss: 0.3085 - val_accuracy: 0.8696\n",
      "Epoch 10/30\n",
      "18316/18316 [==============================] - 7s 398us/step - loss: 0.2763 - accuracy: 0.8844 - val_loss: 0.3034 - val_accuracy: 0.8659\n",
      "Epoch 11/30\n",
      "18316/18316 [==============================] - 7s 398us/step - loss: 0.2712 - accuracy: 0.8856 - val_loss: 0.3215 - val_accuracy: 0.8631\n",
      "Epoch 12/30\n",
      "18316/18316 [==============================] - 7s 397us/step - loss: 0.2852 - accuracy: 0.8799 - val_loss: 0.3152 - val_accuracy: 0.8615\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 13/30\n",
      "18316/18316 [==============================] - 7s 398us/step - loss: 0.2649 - accuracy: 0.8900 - val_loss: 0.2991 - val_accuracy: 0.8720\n",
      "Epoch 14/30\n",
      "18316/18316 [==============================] - 7s 399us/step - loss: 0.2595 - accuracy: 0.8926 - val_loss: 0.3007 - val_accuracy: 0.8720\n",
      "Epoch 15/30\n",
      "18316/18316 [==============================] - 7s 398us/step - loss: 0.2554 - accuracy: 0.8938 - val_loss: 0.2981 - val_accuracy: 0.8722\n",
      "Epoch 16/30\n",
      "18316/18316 [==============================] - 7s 398us/step - loss: 0.2525 - accuracy: 0.8957 - val_loss: 0.2976 - val_accuracy: 0.8736\n",
      "Epoch 17/30\n",
      "18316/18316 [==============================] - 7s 398us/step - loss: 0.2529 - accuracy: 0.8958 - val_loss: 0.2946 - val_accuracy: 0.8727\n",
      "Epoch 18/30\n",
      "18316/18316 [==============================] - 7s 398us/step - loss: 0.2516 - accuracy: 0.8942 - val_loss: 0.2945 - val_accuracy: 0.8725\n",
      "Epoch 19/30\n",
      "18316/18316 [==============================] - 7s 398us/step - loss: 0.2448 - accuracy: 0.8980 - val_loss: 0.2989 - val_accuracy: 0.8690\n",
      "Epoch 20/30\n",
      "18316/18316 [==============================] - 7s 398us/step - loss: 0.2421 - accuracy: 0.8992 - val_loss: 0.2930 - val_accuracy: 0.8718\n",
      "Epoch 21/30\n",
      "18316/18316 [==============================] - 7s 398us/step - loss: 0.2424 - accuracy: 0.8995 - val_loss: 0.2930 - val_accuracy: 0.8725\n",
      "Epoch 22/30\n",
      "18316/18316 [==============================] - 7s 398us/step - loss: 0.2428 - accuracy: 0.8998 - val_loss: 0.2952 - val_accuracy: 0.8764\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 23/30\n",
      "18316/18316 [==============================] - 7s 398us/step - loss: 0.2360 - accuracy: 0.9021 - val_loss: 0.2925 - val_accuracy: 0.8722\n",
      "Epoch 24/30\n",
      "18316/18316 [==============================] - 7s 398us/step - loss: 0.2341 - accuracy: 0.9034 - val_loss: 0.3008 - val_accuracy: 0.8720\n",
      "Epoch 25/30\n",
      "18316/18316 [==============================] - 7s 398us/step - loss: 0.2326 - accuracy: 0.9040 - val_loss: 0.2921 - val_accuracy: 0.8738\n",
      "Epoch 26/30\n",
      "18316/18316 [==============================] - 7s 398us/step - loss: 0.2331 - accuracy: 0.9046 - val_loss: 0.2956 - val_accuracy: 0.8716\n",
      "Epoch 27/30\n",
      "18316/18316 [==============================] - 7s 398us/step - loss: 0.2342 - accuracy: 0.9031 - val_loss: 0.3025 - val_accuracy: 0.8722\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 28/30\n",
      "18316/18316 [==============================] - 7s 398us/step - loss: 0.2310 - accuracy: 0.9040 - val_loss: 0.2931 - val_accuracy: 0.8749\n",
      "Epoch 29/30\n",
      "18316/18316 [==============================] - 7s 399us/step - loss: 0.2277 - accuracy: 0.9063 - val_loss: 0.2904 - val_accuracy: 0.8731\n",
      "Epoch 30/30\n",
      "18316/18316 [==============================] - 7s 398us/step - loss: 0.2277 - accuracy: 0.9067 - val_loss: 0.2917 - val_accuracy: 0.8731\n",
      "score: 29.15\n",
      "Accuracy: 87.42%\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.50, patience=2, verbose=1, mode='auto', cooldown=0, min_lr=0.00001)\n",
    "\n",
    "early = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Conv1D(128, 3, activation='relu',input_shape = (768,1))) # input_shape = (768,1)\n",
    "model1.add(Conv1D(256, 3,  activation='relu'))\n",
    "# flat\n",
    "model1.add(Flatten())\n",
    "\n",
    "model1.add(Dense(2, activation='softmax'))\n",
    "model1.summary()\n",
    "\n",
    "adam = optimizers.Adam( beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "model1.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "history  = model1.fit(np.array(x_train), np.array(y_train),\n",
    " epochs= 30,\n",
    " batch_size = 800,\n",
    " validation_data = (np.array(x_val), np.array(y_val)),\n",
    " callbacks = [reduce_lr, early]\n",
    ")\n",
    "\n",
    "score,acc = model1.evaluate(x_test, y_test, verbose = 2)\n",
    "print(\"score: %.2f\" % (score*100))\n",
    "print(\"Accuracy: %.2f%%\" % (acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 766, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 764, 256)          98560     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 195584)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 195585    \n",
      "=================================================================\n",
      "Total params: 294,657\n",
      "Trainable params: 294,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 18316 samples, validate on 4579 samples\n",
      "Epoch 1/30\n",
      "18316/18316 [==============================] - 7s 408us/step - loss: 0.5774 - accuracy: 0.7026 - val_loss: 0.4662 - val_accuracy: 0.7945\n",
      "Epoch 2/30\n",
      "18316/18316 [==============================] - 7s 397us/step - loss: 0.4308 - accuracy: 0.8080 - val_loss: 0.4096 - val_accuracy: 0.8170\n",
      "Epoch 3/30\n",
      "18316/18316 [==============================] - 7s 397us/step - loss: 0.3779 - accuracy: 0.8335 - val_loss: 0.3625 - val_accuracy: 0.8430\n",
      "Epoch 4/30\n",
      "18316/18316 [==============================] - 7s 397us/step - loss: 0.3434 - accuracy: 0.8513 - val_loss: 0.3572 - val_accuracy: 0.8432\n",
      "Epoch 5/30\n",
      "18316/18316 [==============================] - 7s 398us/step - loss: 0.3242 - accuracy: 0.8608 - val_loss: 0.3374 - val_accuracy: 0.8532\n",
      "Epoch 6/30\n",
      "18316/18316 [==============================] - 7s 397us/step - loss: 0.3182 - accuracy: 0.8618 - val_loss: 0.3602 - val_accuracy: 0.8353\n",
      "Epoch 7/30\n",
      "18316/18316 [==============================] - 7s 397us/step - loss: 0.3030 - accuracy: 0.8686 - val_loss: 0.3119 - val_accuracy: 0.8690\n",
      "Epoch 8/30\n",
      "18316/18316 [==============================] - 7s 397us/step - loss: 0.2849 - accuracy: 0.8781 - val_loss: 0.3496 - val_accuracy: 0.8467\n",
      "Epoch 9/30\n",
      "18316/18316 [==============================] - 7s 397us/step - loss: 0.2770 - accuracy: 0.8829 - val_loss: 0.3027 - val_accuracy: 0.8701\n",
      "Epoch 10/30\n",
      "18316/18316 [==============================] - 7s 397us/step - loss: 0.2706 - accuracy: 0.8865 - val_loss: 0.3082 - val_accuracy: 0.8661\n",
      "Epoch 11/30\n",
      "18316/18316 [==============================] - 7s 397us/step - loss: 0.2610 - accuracy: 0.8901 - val_loss: 0.2977 - val_accuracy: 0.8714\n",
      "Epoch 12/30\n",
      "18316/18316 [==============================] - 7s 397us/step - loss: 0.2684 - accuracy: 0.8837 - val_loss: 0.3338 - val_accuracy: 0.8583\n",
      "Epoch 13/30\n",
      "18316/18316 [==============================] - 7s 397us/step - loss: 0.2576 - accuracy: 0.8922 - val_loss: 0.3170 - val_accuracy: 0.8696\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 14/30\n",
      "18316/18316 [==============================] - 7s 397us/step - loss: 0.2416 - accuracy: 0.8987 - val_loss: 0.2965 - val_accuracy: 0.8712\n",
      "Epoch 15/30\n",
      "18316/18316 [==============================] - 7s 397us/step - loss: 0.2333 - accuracy: 0.9024 - val_loss: 0.3098 - val_accuracy: 0.8639\n",
      "Epoch 16/30\n",
      "18316/18316 [==============================] - 7s 397us/step - loss: 0.2374 - accuracy: 0.8987 - val_loss: 0.3073 - val_accuracy: 0.8653\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 17/30\n",
      "18316/18316 [==============================] - 7s 397us/step - loss: 0.2242 - accuracy: 0.9070 - val_loss: 0.2923 - val_accuracy: 0.8749\n",
      "Epoch 18/30\n",
      "18316/18316 [==============================] - 7s 398us/step - loss: 0.2203 - accuracy: 0.9079 - val_loss: 0.2914 - val_accuracy: 0.8727\n",
      "Epoch 19/30\n",
      "18316/18316 [==============================] - 7s 397us/step - loss: 0.2196 - accuracy: 0.9089 - val_loss: 0.3021 - val_accuracy: 0.8744\n",
      "Epoch 20/30\n",
      "18316/18316 [==============================] - 7s 397us/step - loss: 0.2154 - accuracy: 0.9115 - val_loss: 0.2930 - val_accuracy: 0.8751\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 21/30\n",
      "18316/18316 [==============================] - 7s 397us/step - loss: 0.2119 - accuracy: 0.9122 - val_loss: 0.2983 - val_accuracy: 0.8764\n",
      "Epoch 22/30\n",
      "18316/18316 [==============================] - 7s 398us/step - loss: 0.2133 - accuracy: 0.9117 - val_loss: 0.3032 - val_accuracy: 0.8692\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 23/30\n",
      "18316/18316 [==============================] - 7s 398us/step - loss: 0.2102 - accuracy: 0.9137 - val_loss: 0.2925 - val_accuracy: 0.8736\n",
      "Epoch 00023: early stopping\n",
      "score: 29.35\n",
      "Accuracy: 87.82%\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.50, patience=2, verbose=1, mode='auto', cooldown=0, min_lr=0.00001)\n",
    "\n",
    "early = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Conv1D(128, 3, activation='relu',input_shape = (768,1))) # input_shape = (768,1)\n",
    "model1.add(Conv1D(256, 3,  activation='relu'))\n",
    "# flat\n",
    "model1.add(Flatten())\n",
    "\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "model1.summary()\n",
    "\n",
    "adam = optimizers.Adam( beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "model1.compile(loss='binary_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "history  = model1.fit(np.array(x_train), np.array(y_train),\n",
    " epochs= 30,\n",
    " batch_size = 800,\n",
    " validation_data = (np.array(x_val), np.array(y_val)),\n",
    " callbacks = [reduce_lr, early]\n",
    ")\n",
    "\n",
    "score,acc = model1.evaluate(x_test, y_test, verbose = 2)\n",
    "print(\"score: %.2f\" % (score*100))\n",
    "print(\"Accuracy: %.2f%%\" % (acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
